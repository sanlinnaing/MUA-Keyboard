{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English LSTM Training (GPU/Metal)\n",
    "\n",
    "Train LSTM model for English next-word prediction using TensorFlow Metal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPUs: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Metal: {tf.config.list_physical_devices('Metal') if hasattr(tf.config, 'list_physical_devices') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - adjust these to your setup\n",
    "INPUT_DIR = Path('processed')   # Directory with prepared data\n",
    "OUTPUT_DIR = Path('models')     # Directory for output models\n",
    "\n",
    "# Model parameters (must match Myanmar LSTM for native engine compatibility)\n",
    "EMBEDDING_DIM = 256\n",
    "LSTM_UNITS = 256\n",
    "SEQUENCE_LENGTH = 5\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 128        # Increase for GPU\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.1\n",
    "MAX_SEQUENCES = None    # Set to limit sequences (e.g., 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(INPUT_DIR / 'en_word_indices.json', 'r') as f:\n",
    "    word_to_idx = json.load(f)\n",
    "\n",
    "# Load sequences\n",
    "with open(INPUT_DIR / 'en_sequences.pkl', 'rb') as f:\n",
    "    sequences = pickle.load(f)\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Total sequences: {len(sequences):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally limit sequences\n",
    "if MAX_SEQUENCES and len(sequences) > MAX_SEQUENCES:\n",
    "    print(f\"Limiting to {MAX_SEQUENCES:,} sequences\")\n",
    "    indices = np.random.choice(len(sequences), MAX_SEQUENCES, replace=False)\n",
    "    sequences = [sequences[i] for i in indices]\n",
    "\n",
    "# Convert to numpy (sparse labels - no one-hot!)\n",
    "sequences = np.array(sequences, dtype=np.int32)\n",
    "X = sequences[:, :-1]  # All but last token\n",
    "y = sequences[:, -1]   # Last token (sparse)\n",
    "\n",
    "print(f\"X shape: {X.shape} ({X.nbytes / 1024 / 1024:.1f} MB)\")\n",
    "print(f\"y shape: {y.shape} ({y.nbytes / 1024 / 1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, EMBEDDING_DIM),\n",
    "    LSTM(LSTM_UNITS),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        str(OUTPUT_DIR / 'en_lstm_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(str(OUTPUT_DIR / 'en_lstm_final.keras'))\n",
    "print(f\"Saved to {OUTPUT_DIR / 'en_lstm_final.keras'}\")\n",
    "\n",
    "# Save training history\n",
    "with open(OUTPUT_DIR / 'training_history.json', 'w') as f:\n",
    "    json.dump({k: [float(v) for v in vals] for k, vals in history.history.items()}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {v: k for k, v in word_to_idx.items()}\n",
    "\n",
    "sample_indices = np.random.choice(len(X), min(10, len(X)), replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    input_seq = X[idx]\n",
    "    true_next = y[idx]\n",
    "    \n",
    "    pred = model.predict(input_seq.reshape(1, -1), verbose=0)\n",
    "    pred_idx = np.argmax(pred[0])\n",
    "    \n",
    "    input_words = [idx_to_word.get(i, '<UNK>') for i in input_seq if i != 0]\n",
    "    true_word = idx_to_word.get(true_next, '<UNK>')\n",
    "    pred_word = idx_to_word.get(pred_idx, '<UNK>')\n",
    "    \n",
    "    print(f\"'{' '.join(input_words)}' -> True: '{true_word}', Pred: '{pred_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Train')\n",
    "ax1.plot(history.history['val_loss'], label='Val')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], label='Val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Native Format\n",
    "\n",
    "Run this after training to convert for mobile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export_to_native.py --model models/en_lstm_best.keras --output output/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
